# Model configuration
model: 'gnn'  # Model type to use ('gnn' or 'mlp')
edge_num_hidden_layers: 4  # Number of hidden layers in the edge MLP
edge_hidden_features: 150  # Number of hidden features in the edge MLP
edge_channels_out: 10  # Number of output channels in the edge MLP
node_num_hidden_layers: 4  # Number of hidden layers in the node MLP
node_hidden_features: 50  # Number of hidden features in the node MLP
use_ids: False  # Whether to use node IDs as input features
use_velocity_only: False  # Whether to use only velocities as input features
use_resting_state: False  # Whether to use resting state as input features
use_edge_mlp: True  # Whether to use an edge MLP
use_edge_mlp_diff_features_only: True  # Whether to use difference between features for the edge MLP only
use_alpha: False  # Whether to normalize the state vector by a MLP
link_step: 1 # Number of steps in links to be modeled in the GNN, 1 => 30 links, 2 => 15 links, 3 => 10 links, 10 => 3 links
use_inputs: True  # Whether to use input features
encode_nodes: False  # Whether to encode nodes
encode_inputs: False  # Whether to encode edges
batch_norm: False  # Whether to use batch normalization
layer_norm: False  # Whether to use layer normalization

# Training configuration
learning_rate: 1.0e-3  # Learning rate for optimization
batch_size: 200  # Size of each mini-batch
num_epochs: 2000  # Number of training epochs
weight_decay: 1.0e-7  # Weight decay for optimization (L2 regularization)
l1_weight: 0.0  # L1 regularization for the model
gradient_clipping_max_norm: Null  # Maximum norm for gradient clipping
scheduler_patience: 100  # Patience for learning rate scheduler
shuffle: True  # Whether to shuffle the training data
seed: 0  # Random seed for reproducibility

# Other
log_metrics: False  # Whether to log metrics
dt: 0.01  # Time step for the simulation [s]

# MLP
mlp_num_hidden_layers: 4  # Number of hidden layers in the MLP
mlp_hidden_features: 150  # Number of hidden features in the MLP